{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1032fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextlib\n",
    "\n",
    "import fiftyone as fo\n",
    "import fiftyone.utils.annotations as foa\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from src.datasets.multi_build import build_dataset_from_keys\n",
    "from src.models.segformer_baseline import load_model\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from tqdm.auto import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a8eb91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUILD_KEYS = [\"tcr_phase1_build1\", \"tcr_phase1_build2\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b35a0c",
   "metadata": {},
   "source": [
    "### 1. Dataset & DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c66af39",
   "metadata": {},
   "source": [
    "Just 10 layers for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a70ad729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset sizes: 18 2\n"
     ]
    }
   ],
   "source": [
    "# Build & split\n",
    "full_ds = build_dataset_from_keys(\n",
    "    BUILD_KEYS, size=512, augment=True, layers=range(0, 100, 10)\n",
    ")\n",
    "n_val   = int(len(full_ds)*0.1)\n",
    "n_train = len(full_ds) - n_val\n",
    "train_ds, val_ds = random_split(full_ds, \n",
    "\t\t\t\t\t\t\t\t[n_train,n_val], \n",
    "\t\t\t\t\t\t\t\tgenerator=torch.Generator().manual_seed(42))\n",
    "\n",
    "print(\"dataset sizes:\", len(train_ds), len(val_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1ba872b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "#  Device\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2abc4a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoaders\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=8,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,         # faster host → device copies\n",
    "    prefetch_factor=4,\n",
    "    persistent_workers=True,\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_ds,\n",
    "    batch_size=8,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    prefetch_factor=4,\n",
    "    persistent_workers=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fd0d9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCH   = 8 if device!=\"cpu\" else 4\n",
    "# WORKERS = 4 if device==\"cpu\" else 8\n",
    "# train_loader = DataLoader(train_ds, batch_size=BATCH, shuffle=True,\n",
    "#                           num_workers=WORKERS, pin_memory=(device==\"cuda\"))\n",
    "# val_loader   = DataLoader(val_ds,   batch_size=BATCH, shuffle=False,\n",
    "#                           num_workers=WORKERS, pin_memory=(device==\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6f4201e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batches: 3, Val batches: 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Train batches: {len(train_loader)}, Val batches: {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60844a0",
   "metadata": {},
   "source": [
    "### 2. Model & Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0729a324",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/transformers/utils/deprecation.py:172: UserWarning: The following named arguments are not valid for `SegformerImageProcessor.__init__` and were ignored: 'feature_extractor_type'\n",
      "  return func(*args, **kwargs)\n",
      "Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/segformer-b0-finetuned-ade-512-512 and are newly initialized because the shapes did not match:\n",
      "- decode_head.classifier.bias: found shape torch.Size([150]) in the checkpoint and torch.Size([1]) in the model instantiated\n",
      "- decode_head.classifier.weight: found shape torch.Size([150, 256, 1, 1]) in the checkpoint and torch.Size([1, 256, 1, 1]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load ViT‐SegFormer\n",
    "processor, model = load_model()\n",
    "in_ch = model.decode_head.classifier.in_channels\n",
    "model.decode_head.classifier = nn.Conv2d(in_ch, 2, kernel_size=1)\n",
    "model.config.num_labels = 2\n",
    "model.config.id2label = {0:\"streak\", 1:\"spatter\"}\n",
    "model.config.label2id = {\"streak\":0, \"spatter\":1}\n",
    "model.to(device)\n",
    "\n",
    "# Optimiser + scaler\n",
    "opt    = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-2)\n",
    "scaler = torch.amp.GradScaler(device_type=\"cuda\") if device==\"cuda\" else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f16a156",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, opt, scaler, device, desc=\"train\"):\n",
    "    \"\"\"Returns mean_loss, mean_mIoU across classes 0/1.\"\"\"\n",
    "\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    inter = [0,0]\n",
    "    union = [0,0]\n",
    "    n_batches=0\n",
    "\n",
    "    use_amp = (device==\"cuda\")\n",
    "    def autocast(): return (\n",
    "                torch.amp.autocast(device_type=\"cuda\") \n",
    "                if use_amp else contextlib.nullcontext()\n",
    "    )\n",
    "\n",
    "    for imgs, masks in tqdm(loader, desc=desc, leave=False):\n",
    "        imgs, masks = imgs.to(device), masks.to(device)\n",
    "        imgs = imgs.to(device)\n",
    "        masks = masks.to(device).long()\n",
    "        with autocast():\n",
    "            out = model(pixel_values=imgs).logits          # [B,2,h,w]\n",
    "            out = F.interpolate(out, \n",
    "                                size=masks.shape[-2:], \n",
    "                                mode=\"bilinear\",\n",
    "                                align_corners=False\n",
    "                                )\n",
    "            loss=F.cross_entropy(out, masks)\n",
    "\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "        if use_amp:\n",
    "            scaler.scale(loss).backward(); scaler.step(opt); scaler.update()\n",
    "        else:\n",
    "            loss.backward(); opt.step()\n",
    "\n",
    "        preds = out.argmax(dim=1)\n",
    "        for cls in (0,1):\n",
    "            inter[cls] += int(((preds==cls)&(masks==cls)).sum())\n",
    "            union[cls] += int(((preds==cls)|(masks==cls)).sum())\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        n_batches +=1\n",
    "\n",
    "    miou = sum(inter[i]/(union[i]+1e-6) for i in (0,1))/2\n",
    "    return total_loss/n_batches, miou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b528dae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def eval_one_epoch(model, loader, device, desc=\"val\"):\n",
    "    model.eval()\n",
    "    total_loss=0.0; inter=[0,0]; union=[0,0]; n_batches=0\n",
    "    for imgs, masks in tqdm(loader, desc=desc, leave=False):\n",
    "        imgs, masks = imgs.to(device), masks.to(device)\n",
    "        out = model(pixel_values=imgs).logits\n",
    "        out = F.interpolate(out, \n",
    "                            size=masks.shape[-2:], \n",
    "                            mode=\"bilinear\", \n",
    "                            align_corners=False\n",
    "                            )\n",
    "        loss=F.cross_entropy(out, masks)\n",
    "\n",
    "        preds = out.argmax(dim=1)\n",
    "        for cls in (0,1):\n",
    "            inter[cls] += int(((preds==cls)&(masks==cls)).sum())\n",
    "            union[cls] += int(((preds==cls)|(masks==cls)).sum())\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        n_batches +=1\n",
    "\n",
    "    miou = sum(inter[i]/(union[i]+1e-6) for i in (0,1))/2\n",
    "    return total_loss/n_batches, miou"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef33477",
   "metadata": {},
   "source": [
    "### 4. Quick Epoch Run & History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11615f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9aecf70eee24d5fb8a4ee98bd4e94cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ep0_tr:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "expected scalar type Long but found Float",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m hist = {\u001b[33m\"\u001b[39m\u001b[33mtl\u001b[39m\u001b[33m\"\u001b[39m:[], \u001b[33m\"\u001b[39m\u001b[33mti\u001b[39m\u001b[33m\"\u001b[39m:[],\u001b[33m\"\u001b[39m\u001b[33mvl\u001b[39m\u001b[33m\"\u001b[39m:[],\u001b[33m\"\u001b[39m\u001b[33mvi\u001b[39m\u001b[33m\"\u001b[39m:[]}\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m ep \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(EPOCHS):\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     tl, ti = \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mep\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mep\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m_tr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m     vl, vi = eval_one_epoch(model,   val_loader,   device, desc=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mep\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mep\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_vl\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m     hist[\u001b[33m\"\u001b[39m\u001b[33mtl\u001b[39m\u001b[33m\"\u001b[39m].append(tl); hist[\u001b[33m\"\u001b[39m\u001b[33mti\u001b[39m\u001b[33m\"\u001b[39m].append(ti)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 25\u001b[39m, in \u001b[36mtrain_one_epoch\u001b[39m\u001b[34m(model, loader, opt, scaler, device, desc)\u001b[39m\n\u001b[32m     19\u001b[39m     out = model(pixel_values=imgs).logits          \u001b[38;5;66;03m# [B,2,h,w]\u001b[39;00m\n\u001b[32m     20\u001b[39m     out = F.interpolate(out, \n\u001b[32m     21\u001b[39m                         size=masks.shape[-\u001b[32m2\u001b[39m:], \n\u001b[32m     22\u001b[39m                         mode=\u001b[33m\"\u001b[39m\u001b[33mbilinear\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     23\u001b[39m                         align_corners=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     24\u001b[39m                         )\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m     loss=\u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m opt.zero_grad(set_to_none=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m use_amp:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/torch/nn/functional.py:3494\u001b[39m, in \u001b[36mcross_entropy\u001b[39m\u001b[34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[39m\n\u001b[32m   3492\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   3493\u001b[39m     reduction = _Reduction.legacy_get_string(size_average, reduce)\n\u001b[32m-> \u001b[39m\u001b[32m3494\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_nn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3495\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3496\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3497\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3498\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3499\u001b[39m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3500\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3501\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: expected scalar type Long but found Float"
     ]
    }
   ],
   "source": [
    "EPOCHS=5\n",
    "hist = {\"tl\":[], \"ti\":[],\"vl\":[],\"vi\":[]}\n",
    "\n",
    "for ep in range(EPOCHS):\n",
    "    tl, ti = train_one_epoch(model, train_loader, opt, scaler, device, desc=f\"ep{ep}_tr\")\n",
    "    vl, vi = eval_one_epoch(model,   val_loader,   device, desc=f\"ep{ep}_vl\")\n",
    "    hist[\"tl\"].append(tl); hist[\"ti\"].append(ti)\n",
    "    hist[\"vl\"].append(vl); hist[\"vi\"].append(vi)\n",
    "    print(\n",
    "        f\"Epoch {ep:02d} ▶ train_loss={tl:.3f}, train_iou={ti:.3f} | \"\n",
    "        f\"val_loss={vl:.3f}, val_iou={vi:.3f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b26e407",
   "metadata": {},
   "source": [
    "### 5. Plot Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaed2d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "fig,axes=plt.subplots(1,2,figsize=(10,4))\n",
    "axes[0].plot(hist[\"tl\"], '-o', label=\"train\")\n",
    "axes[0].plot(hist[\"vl\"], '-o', label=\"val\")\n",
    "axes[0].set_title(\"loss\"); axes[0].legend()\n",
    "axes[1].plot(hist[\"ti\"], '-o', label=\"train\")\n",
    "axes[1].plot(hist[\"vi\"], '-o', label=\"val\")\n",
    "axes[1].set_title(\"mIoU\"); axes[1].legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2132f005",
   "metadata": {},
   "source": [
    "### 6. Prediction Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd26299f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick a few from val\n",
    "imgs, masks = next(iter(val_loader))\n",
    "imgs, masks = imgs.to(device), masks\n",
    "\n",
    "with torch.no_grad():\n",
    "    out = model(pixel_values=imgs).logits\n",
    "    out = F.interpolate(out, size=masks.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
    "    preds = out.argmax(dim=1).cpu().numpy()\n",
    "\n",
    "N=4\n",
    "plt.figure(figsize=(12, 9))\n",
    "for i in range(N):\n",
    "    im = imgs[i].cpu().permute(1,2,0).numpy()\n",
    "    gt = masks[i].cpu().numpy()\n",
    "    pr = preds[i]\n",
    "\n",
    "    # map classes to colours: 0=transparent,1=blue,2=red\n",
    "    cmap = {0:(0,0,0,0), 1:(0,0,1,0.4), 2:(1,0,0,0.4)}\n",
    "    overlay_gt = np.zeros((gt.shape[0],gt.shape[1],4))\n",
    "    overlay_pr = np.zeros_like(overlay_gt)\n",
    "    for cls in (1,2):\n",
    "        overlay_gt[gt==cls] = cmap[cls]\n",
    "        overlay_pr[pr==cls] = cmap[cls]\n",
    "\n",
    "    plt.subplot(N,3,3*i+1); plt.imshow(im); \n",
    "    plt.title(\"Image\"); plt.axis(\"off\")\n",
    "    plt.subplot(N,3,3*i+2); plt.imshow(im); \n",
    "    plt.imshow(overlay_gt); plt.title(\"GT\"); plt.axis(\"off\")\n",
    "    plt.subplot(N,3,3*i+3); plt.imshow(im); \n",
    "    plt.imshow(overlay_pr); plt.title(\"Pred\"); plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
